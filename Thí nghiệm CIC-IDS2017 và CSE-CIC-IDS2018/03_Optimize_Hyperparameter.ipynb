{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the models' hyperparameter\n",
    "\n",
    "In this notebook, there is only one goal: optimize the hyperparameters of the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all of the packages that will be used\n",
    "\n",
    "# basic packages for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# packages for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# packages to interpret the training result\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set the random seed to ensure the result is reproducible\n",
    "import random\n",
    "random.seed(10)\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('Dataset/features_selected/CIC-IDS2017_RandomForestClassifier_20.csv').squeeze()\n",
    "features = features[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(649762, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = features.tolist() +  ['Label']\n",
    "\n",
    "cic_ids2017 = pd.read_csv('Dataset/dataset_cleaned/CIC-IDS2017.csv', usecols=columns)\n",
    "cic_ids2017.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down sampling the dataset\n",
    "\n",
    "As grid search is basically brute force all combinations of hyperparameters that are defined in the hyperparameter space, it is an expensive process. To speed up the process, only 10% of the training dataset will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Label\n",
       "malicious    32520\n",
       "benign       32456\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cic_ids2017 = cic_ids2017.sample(frac=0.1).reset_index(drop=True)\n",
    "\n",
    "print('Class distribution: ')\n",
    "cic_ids2017['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "\n",
    "Split the features and the output variable into two dataframe, and further split them into testing and training dataset. The ratio between the training and testing dataset is 8:2 (i.e. 80% for training and 20% for testing). The training dataset will be used to optimize the models' hyperparameter while the testing dataset will give us a first glance on the accuracy of the optimized models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2017_X = cic_ids2017.drop('Label', axis=1).copy()\n",
    "ids2017_y = cic_ids2017['Label'].copy()\n",
    "\n",
    "ids2017_train_X, ids2017_test_X, ids2017_train_y, ids2017_test_y = train_test_split(ids2017_X, ids2017_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "\n",
    "ids2017_train_X_scaled = scalar.fit_transform(ids2017_train_X)\n",
    "ids2017_test_X_scaled = scalar.transform(ids2017_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Hyperparameter of each models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "The decision tree will be optimized by tuning the `ccp_alpha` value. A for loop is being used to loop through multiple `ccp_alpha` values and the alpha value that gives the highest accuracy score will be selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='alpha'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "path = decision_tree.cost_complexity_pruning_path(ids2017_train_X_scaled, ids2017_train_y)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas = ccp_alphas[:-1] # exlude the maximum value\n",
    "\n",
    "alpha_loop_values = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    decision_tree = tree.DecisionTreeClassifier(criterion='entropy', ccp_alpha=ccp_alpha)\n",
    "    scores = cross_val_score(decision_tree, ids2017_train_X_scaled, ids2017_train_y, cv=5)\n",
    "    alpha_loop_values.append([ccp_alpha, np.mean(scores), np.std(scores)])\n",
    "\n",
    "\n",
    "# Plot a graph of the means and standard deviations of the scores for each candidate\n",
    "alpha_results = pd.DataFrame(alpha_loop_values, columns=['alpha', 'mean_accuracy', 'std'])\n",
    "\n",
    "alpha_results.plot(x='alpha', \n",
    "                    y='mean_accuracy', \n",
    "                    yerr='std', \n",
    "                    marker='o', \n",
    "                    linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the optimal tree and evaluate its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha value: 1.4401469385343852e-05\n",
      "Accuracy: 0.99646\n"
     ]
    }
   ],
   "source": [
    "ideal_ccp_alpha = alpha_results.sort_values(by=['mean_accuracy'], ascending=False).iloc[0]\n",
    "ideal_ccp_alpha = float(ideal_ccp_alpha['alpha'])\n",
    "print(f\"Optimal alpha value: {ideal_ccp_alpha}\")\n",
    "\n",
    "# build the optimum tree\n",
    "decision_tree = tree.DecisionTreeClassifier(criterion='entropy', ccp_alpha=ideal_ccp_alpha)\n",
    "decision_tree.fit(ids2017_train_X_scaled, ids2017_train_y)\n",
    "\n",
    "prediction = decision_tree.predict(ids2017_test_X_scaled)\n",
    "accuracy = metrics.accuracy_score(ids2017_test_y, prediction)\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum hyperparameters: \n",
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1e-05, 'min_samples_split': 1e-05, 'n_estimators': 200}\n",
      "CPU times: total: 15.3 s\n",
      "Wall time: 20min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameter_space = [\n",
    "    {'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_leaf': [3, 0.0001, 0.0005, 0.00001], \n",
    "    'min_samples_split': [8, 0.0005, 0.0001, 0.00001], \n",
    "    'n_estimators': [100, 200, 350]\n",
    "    }\n",
    "]\n",
    "\n",
    "optimal_rf = GridSearchCV(\n",
    "                        RandomForestClassifier(),\n",
    "                        parameter_space, \n",
    "                        cv=5,\n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=0\n",
    ")\n",
    "\n",
    "optimal_rf.fit(ids2017_train_X_scaled, ids2017_train_y)\n",
    "rf_optimal_params = optimal_rf.best_params_\n",
    "print(f\"Optimum hyperparameters: \\n{rf_optimal_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99672\n"
     ]
    }
   ],
   "source": [
    "prediction = optimal_rf.predict(ids2017_test_X_scaled)\n",
    "accuracy = metrics.accuracy_score(ids2017_test_y, prediction)\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum hyperparameters: \n",
      "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "CPU times: total: 29 s\n",
      "Wall time: 24min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100],\n",
    "    'gamma': ['scale', 1, 0.1, 'auto'],\n",
    "    'kernel': ['rbf', 'linear', 'sigmoid']}\n",
    "]\n",
    "\n",
    "optimal_svm = GridSearchCV(\n",
    "                        SVC(),\n",
    "                        param_grid, \n",
    "                        cv=5,\n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=0\n",
    ")\n",
    "\n",
    "optimal_svm.fit(ids2017_train_X_scaled, ids2017_train_y)\n",
    "svm_optimal_params = optimal_svm.best_params_\n",
    "print(f\"Optimum hyperparameters: \\n{svm_optimal_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction using the optimum model and evaluate its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95793\n"
     ]
    }
   ],
   "source": [
    "prediction = optimal_svm.predict(ids2017_test_X_scaled)\n",
    "accuracy = metrics.accuracy_score(ids2017_test_y, prediction)\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum hyperparameters: \n",
      "{'var_smoothing': 1.0}\n",
      "CPU times: total: 1.72 s\n",
      "Wall time: 5.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameter_space = [\n",
    "    {'var_smoothing': np.logspace(0, -9, num=100)}\n",
    "]\n",
    "\n",
    "optimal_nb = GridSearchCV(\n",
    "                        GaussianNB(),\n",
    "                        parameter_space, \n",
    "                        cv=5,\n",
    "                        n_jobs=-1,\n",
    "                        verbose=0\n",
    ")\n",
    "\n",
    "optimal_nb.fit(ids2017_train_X_scaled, ids2017_train_y)\n",
    "nb_optimal_params = optimal_nb.best_params_\n",
    "print(f\"Optimum hyperparameters: \\n{nb_optimal_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction using the optimum model and evaluate its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73570\n"
     ]
    }
   ],
   "source": [
    "prediction = optimal_nb.predict(ids2017_test_X_scaled)\n",
    "accuracy = metrics.accuracy_score(ids2017_test_y, prediction)\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum hyperparameters: \n",
      "{'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': (40,), 'solver': 'adam'}\n",
      "CPU times: total: 3min 31s\n",
      "Wall time: 29min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameter_space = [\n",
    "    {'hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.00001]}\n",
    "]\n",
    "\n",
    "ann = MLPClassifier(max_iter=500)\n",
    "\n",
    "optimal_ann = GridSearchCV(\n",
    "                        ann,\n",
    "                        parameter_space, \n",
    "                        cv=5,\n",
    "                        n_jobs=-1,\n",
    "                        verbose=0\n",
    ")\n",
    "\n",
    "optimal_ann.fit(ids2017_train_X_scaled, ids2017_train_y)\n",
    "ann_optimal_params = optimal_ann.best_params_\n",
    "print(f\"Optimum hyperparameters: \\n{ann_optimal_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95239\n"
     ]
    }
   ],
   "source": [
    "prediction = optimal_ann.predict(ids2017_test_X_scaled)\n",
    "accuracy = metrics.accuracy_score(ids2017_test_y, prediction)\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum hyperparameters: \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15, 15, 15), 'solver': 'adam'}\n",
      "CPU times: total: 42.1 s\n",
      "Wall time: 30min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameter_space = [\n",
    "    {'hidden_layer_sizes': [(10,10, 10), (12, 12, 12), (15, 15, 15), (8, 8, 8, 8), (10, 10, 10, 10)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.00001, 0.001]}\n",
    "]\n",
    "\n",
    "dnn = MLPClassifier(max_iter=500)\n",
    "\n",
    "optimal_dnn = GridSearchCV(\n",
    "                        dnn,\n",
    "                        parameter_space, \n",
    "                        cv=5,\n",
    "                        n_jobs=-1,\n",
    "                        verbose=0\n",
    ")\n",
    "\n",
    "optimal_dnn.fit(ids2017_train_X_scaled, ids2017_train_y)\n",
    "dnn_optimal_params = optimal_dnn.best_params_\n",
    "print(f\"Optimum hyperparameters: \\n{dnn_optimal_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97466\n"
     ]
    }
   ],
   "source": [
    "prediction = optimal_dnn.predict(ids2017_test_X_scaled)\n",
    "accuracy = metrics.accuracy_score(ids2017_test_y, prediction)\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44c13dc6c3f21bbb987c14254e5f1628aa054b85b2e38852b8ccc1d4b03a22cf"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
